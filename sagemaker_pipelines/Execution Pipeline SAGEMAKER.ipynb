{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2a8e425-dcd3-4c55-be9d-2d79fa7ad926",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n",
      "INFO:sagemaker.image_uris:Defaulting to only supported image scope: cpu.\n",
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n",
      "INFO:sagemaker.image_uris:Defaulting to only supported image scope: cpu.\n",
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n",
      "INFO:sagemaker.image_uris:Defaulting to only supported image scope: cpu.\n",
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n",
      "INFO:sagemaker.image_uris:Defaulting to only supported image scope: cpu.\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing locally with: \n",
      "  Region: us-east-1\n",
      "  Role: arn:aws:iam::503427799533:role/SGMLOPS\n",
      "  Bucket: albertstats19-mlops-iris-bucket\n",
      "  Model Package Group: IrisModelGroup\n",
      "SageMaker SDK Version: 2.247.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n",
      "INFO:sagemaker.image_uris:Defaulting to only supported image scope: cpu.\n",
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n",
      "INFO:sagemaker.image_uris:Defaulting to only supported image scope: cpu.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo de configuración de registro subido a S3: s3://albertstats19-mlops-iris-bucket/pipeline-configs/iris-mlops-p/register_config.json\n",
      "Upserting SageMaker Pipeline: iris-mlops-p-IrisMLOpsPipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting SageMaker Pipeline execution for: iris-mlops-p-IrisMLOpsPipeline\n",
      "SageMaker Pipeline execution ARN: arn:aws:sagemaker:us-east-1:503427799533:pipeline/iris-mlops-p-IrisMLOpsPipeline/execution/ycoj0fbwqziw\n",
      "SageMaker Pipeline execution initiated. Check SageMaker Pipelines console for status.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "import json\n",
    "import boto3 # Asegúrate de que boto3 está importado\n",
    "from sagemaker.processing import ScriptProcessor, ProcessingInput, ProcessingOutput\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.workflow.steps import ProcessingStep, TrainingStep\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "from sagemaker.workflow.conditions import ConditionLessThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterFloat,\n",
    "    ParameterString,\n",
    ")\n",
    "\n",
    "def get_sagemaker_pipeline(\n",
    "    region: str,\n",
    "    role: str,\n",
    "    default_bucket: str,\n",
    "    base_job_prefix: str,\n",
    "    model_package_group_name: str,\n",
    "    model_accuracy_threshold: float = 0.95, # Umbral de precisión\n",
    "    sample_rate_for_batch_predict: float = 0.1 # Tasa de muestreo para predicciones batch\n",
    ") -> Pipeline:\n",
    "\n",
    "    sagemaker_session = sagemaker.Session(default_bucket=default_bucket)\n",
    "    boto_session = boto3.Session(region_name=region) # Para S3 client\n",
    "\n",
    "    # Parámetros del Pipeline (pueden ser modificados al iniciar el pipeline)\n",
    "    pipeline_model_accuracy_threshold = ParameterFloat(\n",
    "        name=\"ModelAccuracyThreshold\",\n",
    "        default_value=model_accuracy_threshold,\n",
    "    )\n",
    "    pipeline_sample_rate_for_batch_predict = ParameterFloat(\n",
    "        name=\"SampleRateForBatchPredict\",\n",
    "        default_value=sample_rate_for_batch_predict,\n",
    "    )\n",
    "\n",
    "    # --- Paso 1: Obtener Datos (Get Data) ---\n",
    "    get_data_processor = ScriptProcessor(\n",
    "        image_uri=sagemaker.image_uris.retrieve(framework=\"sklearn\", region=region, version=\"1.0-1\"),\n",
    "        role=role,\n",
    "        instance_type=\"ml.m5.large\",\n",
    "        instance_count=1,\n",
    "        base_job_name=f\"{base_job_prefix}-get-data\",\n",
    "        sagemaker_session=sagemaker_session,\n",
    "        command=[\"python3\"], # <--- AGREGADO/CORREGIDO\n",
    "    )\n",
    "    get_data_step = ProcessingStep(\n",
    "        name=\"GetData\",\n",
    "        processor=get_data_processor,\n",
    "        outputs=[ProcessingOutput(source=\"/opt/ml/processing/output\", destination=f\"s3://{default_bucket}/iris-data/raw\")],\n",
    "        code=os.path.join(os.getcwd(), \"../ml_code/get_data.py\"),\n",
    "    )\n",
    "\n",
    "    # --- Paso 2: Preprocesamiento (Preprocess Data) ---\n",
    "    preprocess_processor = ScriptProcessor(\n",
    "        image_uri=sagemaker.image_uris.retrieve(framework=\"sklearn\", region=region, version=\"1.0-1\"),\n",
    "        role=role,\n",
    "        instance_type=\"ml.m5.large\",\n",
    "        instance_count=1,\n",
    "        base_job_name=f\"{base_job_prefix}-preprocess\",\n",
    "        sagemaker_session=sagemaker_session,\n",
    "        command=[\"python3\"], # <--- AGREGADO/CORREGIDO\n",
    "    )\n",
    "    preprocess_step = ProcessingStep(\n",
    "        name=\"PreprocessData\",\n",
    "        processor=preprocess_processor,\n",
    "        inputs=[ProcessingInput(\n",
    "            source=get_data_step.properties.ProcessingOutputConfig.Outputs[\"output\"].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/input\"\n",
    "        )],\n",
    "        outputs=[\n",
    "            ProcessingOutput(source=\"/opt/ml/processing/output\", destination=f\"s3://{default_bucket}/iris-data/processed\"),\n",
    "            ProcessingOutput(source=\"/opt/ml/model\", destination=f\"s3://{default_bucket}/iris-artifacts/scaler\", output_name=\"scaler_model\")\n",
    "        ],\n",
    "        code=os.path.join(os.getcwd(), \"../ml_code/preprocess.py\"),\n",
    "    )\n",
    "\n",
    "    # --- Paso 3: Dividir Datos (Split Data) ---\n",
    "    split_data_processor = ScriptProcessor(\n",
    "        image_uri=sagemaker.image_uris.retrieve(framework=\"sklearn\", region=region, version=\"1.0-1\"),\n",
    "        role=role,\n",
    "        instance_type=\"ml.m5.large\",\n",
    "        instance_count=1,\n",
    "        base_job_name=f\"{base_job_prefix}-split-data\",\n",
    "        sagemaker_session=sagemaker_session,\n",
    "        command=[\"python3\"], # <--- AGREGADO/CORREGIDO\n",
    "    )\n",
    "    split_data_step = ProcessingStep(\n",
    "        name=\"SplitData\",\n",
    "        processor=split_data_processor,\n",
    "        inputs=[ProcessingInput(\n",
    "            source=preprocess_step.properties.ProcessingOutputConfig.Outputs[\"output\"].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/input\"\n",
    "        )],\n",
    "        outputs=[\n",
    "            ProcessingOutput(source=\"/opt/ml/processing/output\", destination=f\"s3://{default_bucket}/iris-data/split\")\n",
    "        ],\n",
    "        code=os.path.join(os.getcwd(), \"../ml_code/split_data.py\"),\n",
    "    )\n",
    "\n",
    "    # --- Paso 4: Entrenamiento (Train Model) ---\n",
    "    sklearn_estimator = SKLearn(\n",
    "        entry_point=os.path.join(os.getcwd(), \"../ml_code/train_model.py\"),\n",
    "        role=role,\n",
    "        instance_type=\"ml.m5.large\",\n",
    "        framework_version=\"1.0-1\",\n",
    "        base_job_name=f\"{base_job_prefix}-train\",\n",
    "        sagemaker_session=sagemaker_session,\n",
    "        output_path=f\"s3://{default_bucket}/iris-artifacts/model\",\n",
    "    )\n",
    "    train_step = TrainingStep(\n",
    "        name=\"TrainModel\",\n",
    "        estimator=sklearn_estimator,\n",
    "        inputs={\n",
    "            \"training\": sagemaker.inputs.TrainingInput(\n",
    "                s3_data=split_data_step.properties.ProcessingOutputConfig.Outputs[\"output\"].S3Output.S3Uri,\n",
    "                content_type=\"text/csv\"\n",
    "            )\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # --- Paso 5: Evaluación (Evaluate Model) ---\n",
    "    evaluation_processor = ScriptProcessor(\n",
    "        image_uri=sagemaker.image_uris.retrieve(framework=\"sklearn\", region=region, version=\"1.0-1\"),\n",
    "        role=role,\n",
    "        instance_type=\"ml.m5.large\",\n",
    "        instance_count=1,\n",
    "        base_job_name=f\"{base_job_prefix}-evaluate\",\n",
    "        sagemaker_session=sagemaker_session,\n",
    "        command=[\"python3\"], # <--- AGREGADO/CORREGIDO\n",
    "    )\n",
    "    \n",
    "    evaluation_report = PropertyFile(\n",
    "        name=\"EvaluationReport\",\n",
    "        output_name=\"evaluation\",\n",
    "        path=\"evaluation.json\",\n",
    "    )\n",
    "\n",
    "    evaluate_step = ProcessingStep(\n",
    "        name=\"EvaluateModel\",\n",
    "        processor=evaluation_processor,\n",
    "        inputs=[\n",
    "            ProcessingInput(\n",
    "                source=train_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "                destination=\"/opt/ml/processing/model\",\n",
    "            ),\n",
    "            ProcessingInput(\n",
    "                source=split_data_step.properties.ProcessingOutputConfig.Outputs[\"output\"].S3Output.S3Uri,\n",
    "                destination=\"/opt/ml/processing/input\",\n",
    "            ),\n",
    "        ],\n",
    "        outputs=[\n",
    "            ProcessingOutput(\n",
    "                source=\"/opt/ml/processing/output\", \n",
    "                destination=f\"s3://{default_bucket}/iris-artifacts/evaluation_report\",\n",
    "                output_name=\"evaluation\"\n",
    "            )\n",
    "        ],\n",
    "        code=os.path.join(os.getcwd(), \"../ml_code/evaluate_model.py\"),\n",
    "        property_files=[evaluation_report],\n",
    "    )\n",
    "\n",
    "    # --- Configuración para el paso de Registro del Modelo ---\n",
    "    # Crearemos un archivo JSON temporal con la configuración para el registro\n",
    "    # y lo subiremos a S3 para que el script de registro lo lea.\n",
    "    # Esto evita el problema de los 'arguments' en ProcessingStep.\n",
    "    register_config_data = {\n",
    "        \"model_package_group_name\": model_package_group_name,\n",
    "        \"region\": region,\n",
    "        \"role_arn\": role, # Aunque el script lo puede inferir, lo pasamos para ser explícitos\n",
    "    }\n",
    "    \n",
    "    # Ruta local para el archivo de configuración temporal\n",
    "    config_dir = \"temp_config\"\n",
    "    os.makedirs(config_dir, exist_ok=True)\n",
    "    register_config_file_name = \"register_config.json\"\n",
    "    register_config_file_path = os.path.join(config_dir, register_config_file_name)\n",
    "\n",
    "    with open(register_config_file_path, \"w\") as f:\n",
    "        json.dump(register_config_data, f)\n",
    "    \n",
    "    # Subir el archivo de configuración a S3\n",
    "    s3_client = boto_session.client(\"s3\")\n",
    "    s3_config_uri = f\"s3://{default_bucket}/pipeline-configs/{base_job_prefix}/{register_config_file_name}\"\n",
    "    s3_client.upload_file(register_config_file_path, default_bucket, f\"pipeline-configs/{base_job_prefix}/{register_config_file_name}\")\n",
    "    print(f\"Archivo de configuración de registro subido a S3: {s3_config_uri}\")\n",
    "\n",
    "\n",
    "    # --- Paso 6: REGISTRO DEL MODELO ---\n",
    "    register_model_processor = ScriptProcessor(\n",
    "        image_uri=sagemaker.image_uris.retrieve(framework=\"sklearn\", region=region, version=\"1.0-1\"),\n",
    "        role=role,\n",
    "        instance_type=\"ml.m5.large\",\n",
    "        instance_count=1,\n",
    "        base_job_name=f\"{base_job_prefix}-register-model\",\n",
    "        sagemaker_session=sagemaker_session,\n",
    "        command=[\"python3\"], # <--- AGREGADO/CORREGIDO\n",
    "        # NO DEBE LLEVAR 'arguments' ni 'container_arguments' AQUÍ\n",
    "        # Ya que el script leerá de un archivo de configuración.\n",
    "    )\n",
    "\n",
    "    register_model_step = ProcessingStep(\n",
    "        name=\"RegisterModel\",\n",
    "        processor=register_model_processor,\n",
    "        inputs=[\n",
    "            ProcessingInput(\n",
    "                source=train_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "                destination=\"/opt/ml/processing/model_data\",\n",
    "                input_name=\"model_data\" # Nombre de la entrada para SM_CHANNEL_MODEL_DATA_S3_URI\n",
    "            ),\n",
    "            # NUEVA ENTRADA para el archivo de configuración\n",
    "            ProcessingInput(\n",
    "                source=s3_config_uri,\n",
    "                destination=\"/opt/ml/processing/config\",\n",
    "                input_name=\"config\" # Nombre de la entrada para SM_CHANNEL_CONFIG_S3_URI\n",
    "            ),\n",
    "             ProcessingInput(\n",
    "                source=evaluate_step.properties.ProcessingOutputConfig.Outputs[\"evaluation\"].S3Output.S3Uri,\n",
    "                destination=\"/opt/ml/processing/evaluation\",\n",
    "                input_name=\"evaluation\"\n",
    "            )\n",
    "        ],\n",
    "        code=os.path.join(os.getcwd(), \"../ml_code/register_model.py\"), \n",
    "        # ELIMINADO: 'arguments' o 'container_arguments' ya no van aquí.\n",
    "    )\n",
    "    \n",
    "    # --- Paso 7: Generar Predicciones Batch (Batch Predict) ---\n",
    "    batch_predict_processor = ScriptProcessor(\n",
    "        image_uri=sagemaker.image_uris.retrieve(framework=\"sklearn\", region=region, version=\"1.0-1\"),\n",
    "        role=role,\n",
    "        instance_type=\"ml.m5.large\",\n",
    "        instance_count=1,\n",
    "        base_job_name=f\"{base_job_prefix}-batch-predict\",\n",
    "        sagemaker_session=sagemaker_session,\n",
    "        command=[\"python3\"], # <--- AGREGADO/CORREGIDO\n",
    "    )\n",
    "    batch_predict_step = ProcessingStep(\n",
    "        name=\"GenerateBatchPredictions\",\n",
    "        processor=batch_predict_processor,\n",
    "        inputs=[\n",
    "            ProcessingInput(\n",
    "                source=train_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "                destination=\"/opt/ml/processing/model\"\n",
    "            ),\n",
    "            ProcessingInput(\n",
    "                source=preprocess_step.properties.ProcessingOutputConfig.Outputs[\"output\"].S3Output.S3Uri,\n",
    "                destination=\"/opt/ml/processing/input\"\n",
    "            ),\n",
    "            ProcessingInput(\n",
    "                source=f\"s3://{default_bucket}/config\", # Asumiendo que este 'config' ya existe o se creará aparte\n",
    "                destination=\"/opt/ml/processing/config\"\n",
    "            )\n",
    "        ],\n",
    "        outputs=[\n",
    "            ProcessingOutput(source=\"/opt/ml/processing/output\", destination=f\"s3://{default_bucket}/iris-predictions/batch\")\n",
    "        ],\n",
    "        code=os.path.join(os.getcwd(), \"../ml_code/batch_predict.py\"),\n",
    "    )\n",
    "\n",
    "    # Agrupamos los pasos condicionales\n",
    "    model_accuracy = JsonGet(\n",
    "        step_name=evaluate_step.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"metrics.test_accuracy.value\"\n",
    "    )\n",
    "    cond_gt_equal = ConditionLessThanOrEqualTo(left=pipeline_model_accuracy_threshold, right=model_accuracy)\n",
    "\n",
    "    condition_step = ConditionStep(\n",
    "        name=\"CheckModelAccuracyAndRegister\",\n",
    "        conditions=[cond_gt_equal],\n",
    "        if_steps=[register_model_step, batch_predict_step], # Ambos pasos se ejecutan si la condición es verdadera\n",
    "        else_steps=[],\n",
    "    )\n",
    "\n",
    "    # Define el pipeline principal\n",
    "    pipeline = Pipeline(\n",
    "        name=f\"{base_job_prefix}-IrisMLOpsPipeline\",\n",
    "        parameters=[\n",
    "            pipeline_model_accuracy_threshold,\n",
    "            pipeline_sample_rate_for_batch_predict\n",
    "        ],\n",
    "        steps=[\n",
    "            get_data_step,\n",
    "            preprocess_step,\n",
    "            split_data_step,\n",
    "            train_step,\n",
    "            evaluate_step,\n",
    "            condition_step\n",
    "        ],\n",
    "        sagemaker_session=sagemaker_session,\n",
    "    )\n",
    "    return pipeline\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    region = \"us-east-1\"\n",
    "    role = \"arn:aws:iam::503427799533:role/SGMLOPS\"\n",
    "    default_bucket = \"albertstats19-mlops-iris-bucket\"\n",
    "    base_job_prefix = \"iris-mlops-p\"    \n",
    "    model_package_group_name = \"IrisModelGroup\"\n",
    "    \n",
    "    print(f\"Executing locally with: \")\n",
    "    print(f\"  Region: {region}\")\n",
    "    print(f\"  Role: {role}\")\n",
    "    print(f\"  Bucket: {default_bucket}\")\n",
    "    print(f\"  Model Package Group: {model_package_group_name}\")\n",
    "\n",
    "    # Diagnóstico: Imprimir la versión del SDK de SageMaker\n",
    "    print(f\"SageMaker SDK Version: {sagemaker.__version__}\")\n",
    "\n",
    "    pipeline = get_sagemaker_pipeline(\n",
    "        region=region,\n",
    "        role=role,\n",
    "        default_bucket=default_bucket,\n",
    "        base_job_prefix=base_job_prefix,\n",
    "        model_package_group_name=model_package_group_name,\n",
    "    )\n",
    "    \n",
    "    print(f\"Upserting SageMaker Pipeline: {pipeline.name}\")\n",
    "    pipeline.upsert(role_arn=role)\n",
    "\n",
    "    print(f\"Starting SageMaker Pipeline execution for: {pipeline.name}\")\n",
    "    execution = pipeline.start()\n",
    "    print(f\"SageMaker Pipeline execution ARN: {execution.arn}\")\n",
    "    print(\"SageMaker Pipeline execution initiated. Check SageMaker Pipelines console for status.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5efd413-8da2-4e5a-bf22-42c16c918356",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
